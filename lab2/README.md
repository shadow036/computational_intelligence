# NOTATION:
-> candidate solution/c_solutions: [L0, L1, ..., Lm] where L# is a list of numbers waiting to be evaluated
-> evaluated solution/e_solutions: candidate solution after being evaluated (can be optimal or not, complete or not)
-> incomplete solution: evaluated solution with missing numbers (and thus not optimal as well)
-> complete solution: evaluated solution containing all numbers at least once (not necessarily the optimal one)
-> optimal solution: complete evaluated solution ideally having the highest fitness of all 
    (even though we cannot be sure since we have a limited number of generations)
-> offspring: candidate solution generated by mixing characteristics of two evaluated solutions
-> parent: evaluated solution

# PARTIAL FITNESS FUNCTION (phases.py - line 47)
for each element 'i' of the counters list (phases.py - line 44):
    -> if it contains 1 (=> 1 occurrence of number 'i' in the candidate solution) 
        => fitness = fitness + 1;
    -> if it contains 0 (=> no occurrences of number 'i' in the candidate solution) 
        => fitness = fitness + 0;
    -> if it contains j > 1 (=> more than 1 occurences of number 'i' in the candidate solution) 
        => fitness = fitness - number of occurences above 1

# OFFSET EXPLANATION (phases.py - line 49)
if the candidate solution doesn't contain all required numbers it is not acceptable;
it is better to have a complete solution with partial_fitness < N - 1 with respect of having an incomplete solution with partial_fitness N - 1.
we can picture the counters.count(0) as being an offset equal to -infinity if > 0 added to the partial fitness value described above

# MUTATIONS
in order to have more variety I have chosen to apply 3 different mutations:
    0) remove a sublist if there is more than 1 sublist
    1) substitute a sublist
    2) add a sublist

In the beginning I try to favor exploration by increasing the chance of more "extreme" mutations, specifically the ones which aim to increase the length of a list and thus increasing the possibility of a better fitness.
At a certain point in which the fitness has increased for a while, I try to balance exploration and exploitation strategies by giving an equal chance to conservative mutation (substitute a sublist with another one) and aggressive one (adding additional sublists), in order to not increase too much the amount of sublists and generate a high number of duplicate values.
When the fitness level is very high I stick to adopt a more conservative approach by favoring the simple switch of one sublist to another one.
In all these three cases I always add a small chance of removing a sublist in an attempt to backtrack if all current solutions are very bad.

# RESULTS
Unfortunately the results I have obtained are very bad in the sense that this works only in the case of low N:
in the case of N=5 and N=10 the algorithm is able to reach the optimal (bloat = 0%) solution in a very small number of generations, for N=20 it reaches a good solution (bloat=35%) very fast but for N greater than 90 it fails since at a certain point all individuals have the same genome and so there is no more variety.
I don't know if this behaviour is due to a bug in the code or if the whole approach I took is bad.
One thing that I noticed is that the comma strategy is in general much more efficient with respect to the plus one in this case.